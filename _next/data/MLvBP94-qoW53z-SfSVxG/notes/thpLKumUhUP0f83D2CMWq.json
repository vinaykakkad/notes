{"pageProps":{"note":{"id":"thpLKumUhUP0f83D2CMWq","title":"8-MLE-2","desc":"","updated":1644386683578,"created":1644211663972,"custom":{},"fname":"acads.sem-6.machine-learning.8-MLE-2","type":"note","vault":{"fsPath":"vault"},"contentHash":"f861b00dd977ef0e21ea6005ae6a1e1b","links":[],"anchors":{"model-fitting-or-training":{"type":"header","text":"Model Fitting or Training","value":"model-fitting-or-training","line":8,"column":0,"depth":1},"maximum-likelihood-estimation":{"type":"header","text":"Maximum Likelihood Estimation","value":"maximum-likelihood-estimation","line":13,"column":0,"depth":2},"optimal-theta-for-unsupervisedunconditional-models":{"type":"header","text":"Optimal theta for unsupervised(unconditional) models","value":"optimal-theta-for-unsupervisedunconditional-models","line":35,"column":0,"depth":4},"example-mle-for-bernoulli-distribution":{"type":"header","text":"Example: MLE for Bernoulli distribution","value":"example-mle-for-bernoulli-distribution","line":42,"column":0,"depth":3}},"children":[],"parent":"TN2l8VL0nEIPfVAADRxm5","data":{}},"body":"<h1 id=\"8-mle-2\">8-MLE-2<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#8-mle-2\"></a></h1>\n<h1 id=\"model-fitting-or-training\">Model Fitting or Training<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#model-fitting-or-training\"></a></h1>\n<ul>\n<li>estimating <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Î¸</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span></span></span></span></span> from a given data\n<ul>\n<li>we estimate it by minimizing the loss function <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi><mo stretchy=\"false\">(</mo><mi>Î¸</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span><span class=\"mclose\">)</span></span></span></span></span></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"maximum-likelihood-estimation\">Maximum Likelihood Estimation<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#maximum-likelihood-estimation\"></a></h2>\n<ul>\n<li>we pick the parameters that assign highest probability to the training data</li>\n<li>we define MLE as</li>\n<li><img src=\"/notes/assets/images/2022-02-07-11-43-45.png\"></li>\n<li>we assume that the training examples are independently sampled from the same distribution, ie <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">iid</code>(indpendent and identically distributed)</li>\n<li>the conditional likelihood then becomes</li>\n<li><img src=\"/notes/assets/images/2022-02-07-11-50-56.png\">\n<ul>\n<li><strong><em>as the examples are independent, the overall probability can be expressed as the product of individual probabilities</em></strong></li>\n</ul>\n</li>\n<li>We use a log likelihood:</li>\n<li><img src=\"/notes/assets/images/2022-02-07-11-54-31.png\">\n<ul>\n<li>it is mathematically convenient to use log function as the likelihood can be expessed as summation</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi></mrow><annotation encoding=\"application/x-tex\">log</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span> is a monotonically increasing function and provides one to one mapping</li>\n</ul>\n</li>\n<li>The <em>MLE</em> is then given by:</li>\n<li><img src=\"/notes/assets/images/2022-02-07-11-56-51.png\"></li>\n</ul>\n<br>\n<ul>\n<li>most of the cost functions are designed to <em>minimize</em> const function, we can redfine objective function to be a <em>negative log likelihood</em> or <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">NLL</code></li>\n<li><img src=\"/notes/assets/images/2022-02-07-11-58-41.png\"></li>\n<li>minimizing this gives us the <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><msub><mi>Î¸</mi><mrow><mi>m</mi><mi>l</mi><mi>e</mi></mrow></msub><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{\\theta_{mle}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1079em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9579em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">e</span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.2634em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n</ul>\n<h4 id=\"optimal-theta-for-unsupervisedunconditional-models\">Optimal theta for unsupervised(unconditional) models<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#optimal-theta-for-unsupervisedunconditional-models\"></a></h4>\n<ul>\n<li>as we only have outputs and no inputs in this case, MLE becomes</li>\n<li><img src=\"/notes/assets/images/2022-02-08-08-02-15.png\"></li>\n<li>alternatively, we can maximize the <em>join likelihood</em> of inputs and outputs. The MLE in this case becomes</li>\n<li><img src=\"/notes/assets/images/2022-02-08-08-07-39.png\"></li>\n</ul>\n<h3 id=\"example-mle-for-bernoulli-distribution\">Example: MLE for Bernoulli distribution<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#example-mle-for-bernoulli-distribution\"></a></h3>\n<ul>\n<li>Y is <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">RV</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span> representing a coin toss\n<ul>\n<li>Y = 1 corresponds to heads</li>\n<li>Y = 0 cooresponds to tails</li>\n</ul>\n</li>\n<li>Let <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Î¸</mi><mo>=</mo><mi>p</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\theta = p(Y=1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></span> be the probability of heads</li>\n<li>MLE for such a <em>bernoulli dist.</em> can be given by:</li>\n<li><img src=\"/notes/assets/images/2022-02-08-08-19-06.png\"></li>\n<li>finding the derviative and setting it to 0, we get</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><msub><mi>Î¸</mi><mrow><mi>m</mi><mi>l</mi><mi>e</mi></mrow></msub><mo>^</mo></mover><mo>=</mo><mfrac><msub><mi>N</mi><mi>h</mi></msub><mrow><msub><mi>N</mi><mi>h</mi></msub><mo>+</mo><msub><mi>N</mi><mi>t</mi></msub></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{\\theta_{mle}} = \\frac{N_h}{N_h + N_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1079em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9579em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">e</span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.2634em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3451em;vertical-align:-0.4509em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8942em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:-0.109em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2963em;\"><span style=\"top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4159em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:-0.109em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4509em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>, which is similar to intuitive result</li>\n</ul>\n<br>\n<ul>\n<li><strong>Here we have not incoporated <em>population risk</em> and thus there is a high change of overfitting the training set</strong>\n<ul>\n<li>The model in this case has enough parameters to perfectly fit the observed training data</li>\n</ul>\n</li>\n</ul>","noteIndex":{"id":"LBE6GBZjFtOaX27nwRSpq","title":"Notes ðŸ“š","desc":"","updated":1642916746120,"created":1642875904363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"f3ab1afac9d88a8f51c98f4e257b81a2","links":[],"anchors":{},"children":["H8OS9Ap2DDjZ7XSIZWpQT","m2fe4910vhlj3cwsbw45wfc","tpmpx2xkasjhbntai7ejfx3","ydBpHsjLwIGYomDZo8NtB","g9m1mlmymq7qvcjzi8ap2qu"],"parent":null,"data":{},"body":"\n![home](/assets/images/home.png)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.83.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"theme":"custom"},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/notes","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://vinaykakkad.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"Notes","description":"Notes"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enablePrettyLinks":true,"enableTaskNotes":true,"theme":"custom","searchMode":"lookup","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}