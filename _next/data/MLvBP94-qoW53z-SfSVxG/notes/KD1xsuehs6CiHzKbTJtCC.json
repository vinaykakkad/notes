{"pageProps":{"note":{"id":"KD1xsuehs6CiHzKbTJtCC","title":"1-Introduction","desc":"","updated":1642884276822,"created":1642880535091,"custom":{},"fname":"acads.sem-6.machine-learning.1-Introduction","type":"note","vault":{"fsPath":"vault"},"contentHash":"3e0edcded83a6458fd5b2f988b7434c2","links":[],"anchors":{"pillars-of-the-course":{"type":"header","text":"Pillars of the course","value":"pillars-of-the-course","line":7,"column":0,"depth":1},"what-is-machine-learning":{"type":"header","text":"What is machine learning","value":"what-is-machine-learning","line":14,"column":0,"depth":1},"probabilistic-approach-for-ml":{"type":"header","text":"Probabilistic approach for ML","value":"probabilistic-approach-for-ml","line":20,"column":0,"depth":1},"supervised-machine-learning":{"type":"header","text":"Supervised Machine Learning","value":"supervised-machine-learning","line":28,"column":0,"depth":1},"classification-problem":{"type":"header","text":"Classification Problem","value":"classification-problem","line":33,"column":0,"depth":2},"iris-flowers-dataset":{"type":"header","text":"IRIS flowers dataset","value":"iris-flowers-dataset","line":39,"column":0,"depth":3},"eda-note":{"type":"header","text":"EDA note","value":"eda-note","line":62,"column":0,"depth":3},"empricialexperimental-risk-minimisation":{"type":"header","text":"Empricial(experimental) Risk Minimisation","value":"empricialexperimental-risk-minimisation","line":72,"column":0,"depth":1},"missclassification-rate":{"type":"header","text":"Missclassification Rate","value":"missclassification-rate","line":74,"column":0,"depth":2},"model-fitting-or-training":{"type":"header","text":"Model Fitting or Training","value":"model-fitting-or-training","line":90,"column":0,"depth":2},"todos":{"type":"header","text":"TODOs","value":"todos","line":96,"column":0,"depth":1}},"children":[],"parent":"TN2l8VL0nEIPfVAADRxm5","data":{}},"body":"<h1 id=\"1-introduction\">1-Introduction<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#1-introduction\"></a></h1>\n<h1 id=\"pillars-of-the-course\">Pillars of the course<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pillars-of-the-course\"></a></h1>\n<ul>\n<li>classifcation</li>\n<li>regression</li>\n<li>dimensionality reduction</li>\n<li>clustering</li>\n</ul>\n<h1 id=\"what-is-machine-learning\">What is machine learning<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#what-is-machine-learning\"></a></h1>\n<p>John Mitchell' definition</p>\n<blockquote style=\"background-color: #43b02a20; padding:3px 2px; border-radius: 5px; border-left: 0.25em solid #43b02a; padding-left: 0.75em\">A computer program is said to learn from an experience <b>E</b>, with respect to some task <b>T</b> and using some performance measure <b>P</b>, if its pefromance improves with experience\n</blockquote>\n<h1 id=\"probabilistic-approach-for-ml\">Probabilistic approach for ML<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#probabilistic-approach-for-ml\"></a></h1>\n<ul>\n<li>treat every unknown quantity as a <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">RV</code></li>\n<li>use different proability distributions to model that uncertainity</li>\n<li>we use probabilistic approach because:\n<ul>\n<li>it is optimal decision making strategy under some uncertainity</li>\n<li>other areas of science and engineerig also use the same approach</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"supervised-machine-learning\">Supervised Machine Learning<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#supervised-machine-learning\"></a></h1>\n<ul>\n<li>data with outputs corresponding to inputs is provided</li>\n<li>we try to find the mapping between theese inputs and outputs</li>\n</ul>\n<h2 id=\"classification-problem\">Classification Problem<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#classification-problem\"></a></h2>\n<ul>\n<li>output space is a set of c <em>distinct</em> and <em>mutually exclusive</em> <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">labels</code></li>\n<li>output is a <em>categorical variable</em></li>\n<li>the problem is also called <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">pattern recognition</code></li>\n</ul>\n<h3 id=\"iris-flowers-dataset\">IRIS flowers dataset<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#iris-flowers-dataset\"></a></h3>\n<ul>\n<li>\n<p>labels:</p>\n<ol>\n<li>setosa</li>\n<li>versicolor</li>\n<li>virginica</li>\n</ol>\n</li>\n<li>\n<p>featues:</p>\n<ol>\n<li>petal length</li>\n<li>petal width</li>\n<li>sepal width</li>\n<li>sepal length</li>\n</ol>\n</li>\n<li>\n<p>In cases similar to this, when the size is fixed, the data is stored using <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">design matrix</code></p>\n</li>\n<li>\n<p>Such a dataset is <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">tabular data</code></p>\n</li>\n<li>\n<p>when the inputs are of variable size we may need to store the data in some other format</p>\n</li>\n</ul>\n<p><img src=\"/notes/assets/images/2022-01-14-23-01-57.png\" alt=\"Pairwise Scatter Plot for Iris Dataset\"></p>\n<ul class=\"contains-task-list\">\n<li>pairwise scatter plot for iris dataset</li>\n<li>the diagonal shows the probability distribution for that particular <em>predictor</em></li>\n<li>from this we can get intution for decision rules\n<ul>\n<li>ex: if petal length exceeds some limit, it won't be of a particular type</li>\n</ul>\n</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://github.com/vinaykakkad/pyprobml/blob/master/scripts/iris_plot.py\">code for the scatter plot</a></li>\n</ul>\n<h3 id=\"eda-note\">EDA note<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#eda-note\"></a></h3>\n<ul>\n<li>for such datasets with very few predictors, it is common to plot such pair plots to get the intution</li>\n<li>for datasets with high number of predictors, <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">dimensionality reduction is performed</code></li>\n</ul>\n<p><img src=\"/notes/assets/images/2022-01-14-23-11-37.png\" alt=\"Decision Tree\"></p>\n<ul class=\"contains-task-list\">\n<li>decision tree for the iris dataset</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://github.com/vinaykakkad/pyprobml/blob/master/scripts/iris_dtree.py\">code_1 for decision tree</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://github.com/vinaykakkad/pyprobml/blob/master/scripts/iris_dtree2.py\">code_2 for decision tree</a></li>\n</ul>\n<h1 id=\"empricialexperimental-risk-minimisation\">Empricial(experimental) Risk Minimisation<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#empricialexperimental-risk-minimisation\"></a></h1>\n<h2 id=\"missclassification-rate\">Missclassification Rate<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#missclassification-rate\"></a></h2>\n<ul>\n<li>in the above example, error in the model can be expressed as missclassifcation rate which is given by:</li>\n<li><img src=\"/notes/assets/images/2022-01-16-14-05-56.png\" alt=\"Misclassification Rate\">\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Î¸</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>a</mi><mi>r</mi><mi>a</mi><mi>m</mi><mi>e</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\theta(parameters)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">am</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">ers</span><span class=\"mclose\">)</span></span></span></span></span> are the decision rules that we make </li>\n<li>in case of linear regression, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Î¸</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span></span></span></span></span> are the weights that we assign to the predictors</li>\n</ul>\n</li>\n<li>Here <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>I</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">I(e)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07847em;\">I</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mclose\">)</span></span></span></span></span> is the binary indicator function, which return when the output return by our model does not match the actual output</li>\n<li><img src=\"/notes/assets/images/2022-01-16-14-07-57.png\" alt=\"Indicator function\"></li>\n</ul>\n<br>\n<ul>\n<li>here we assume that each incorrect prediction has the same loss</li>\n<li>in general, we can define a <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">loss function</code>, which is a function of the predicted output and actual output on the training set</li>\n<li>the <em>empirical risk</em> is then defined as:</li>\n<li><img src=\"/notes/assets/images/2022-01-16-14-22-51.png\" alt=\"Empirical Risk\"></li>\n</ul>\n<h2 id=\"model-fitting-or-training\">Model Fitting or Training<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#model-fitting-or-training\"></a></h2>\n<ul>\n<li>one way is to find <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Î¸</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">Î¸</span></span></span></span></span> that minimize the empirical risk (<em>empirical risk minimization</em>)</li>\n<li><img src=\"/notes/assets/images/2022-01-16-14-31-19.png\" alt=\"ERM\"></li>\n<li>true goal: <em>minimize the loss on future data</em> - <code style=\"background-color: #43b02a40; padding:3px 2px; border-radius: 5px\">generalization</code></li>\n</ul>\n<h1 id=\"todos\">TODOs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#todos\"></a></h1>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> ISLR</p>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Random Variables</p>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Tranformation of RVs</p>\n</li>\n<li class=\"task-list-item\">\n<p><input type=\"checkbox\" disabled> Diff probability distribution</p>\n</li>\n</ul>","noteIndex":{"id":"LBE6GBZjFtOaX27nwRSpq","title":"Notes ðŸ“š","desc":"","updated":1642916746120,"created":1642875904363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"f3ab1afac9d88a8f51c98f4e257b81a2","links":[],"anchors":{},"children":["H8OS9Ap2DDjZ7XSIZWpQT","m2fe4910vhlj3cwsbw45wfc","tpmpx2xkasjhbntai7ejfx3","ydBpHsjLwIGYomDZo8NtB","g9m1mlmymq7qvcjzi8ap2qu"],"parent":null,"data":{},"body":"\n![home](/assets/images/home.png)\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.83.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"theme":"custom"},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"assetsPrefix":"/notes","copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://vinaykakkad.github.io","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"Notes","description":"Notes"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enablePrettyLinks":true,"enableTaskNotes":true,"theme":"custom","searchMode":"lookup","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}