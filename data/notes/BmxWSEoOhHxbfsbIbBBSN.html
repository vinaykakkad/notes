<h1 id="2-mle-and-regression">2-MLE-and-regression<a aria-hidden="true" class="anchor-heading icon-link" href="#2-mle-and-regression"></a></h1>
<h2 id="capturing-uncertainity">Capturing Uncertainity<a aria-hidden="true" class="anchor-heading icon-link" href="#capturing-uncertainity"></a></h2>
<ul class="contains-task-list">
<li>in most of the cases, we can't predict perfectly due to:
<ul>
<li><em>intrinsic(irreducible) uncertainity</em>: due to error in data collection...</li>
<li><em>model uncertainity</em>: due to absence of infinite data / processing power</li>
</ul>
</li>
<li>We capture this uncertainity using conditional probability</li>
<li><img src="/notes/assets/images/2022-01-16-15-52-52.png" alt="capturing uncertainity"></li>
<li>here <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><mi>X</mi><mo>→</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">]</mo><mi>c</mi></msup></mrow><annotation encoding="application/x-tex">f: X \rightarrow [0, 1]^c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span></span></span></span></span> maps the input to one of the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span> labels
<ul>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span></span> follows the axioms of probability:
<ul>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><msub><mi>f</mi><mi>c</mi></msub><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \leq f_c \leq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span></li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle scriptlevel="0" displaystyle="false"><msubsup><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>f</mi><mi>c</mi></msub><mo>=</mo><mn>1</mn></mstyle></mrow><annotation encoding="application/x-tex">\textstyle\sum_{c=1}^n f_c = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.104em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span></li>
</ul>
</li>
</ul>
</li>
<li class="task-list-item"><input type="checkbox" disabled> restriction and <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">softmax function</code></li>
<li class="task-list-item"><input type="checkbox" disabled> <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">affine functions</code> and notations</li>
</ul>
<h2 id="maximum-likelihood-estimation">Maximum Likelihood Estimation<a aria-hidden="true" class="anchor-heading icon-link" href="#maximum-likelihood-estimation"></a></h2>
<ul class="contains-task-list">
<li>A common loss function for probabilistic models is <em>negative log probability</em></li>
<li><img src="/notes/assets/images/2022-01-16-16-05-35.png" alt="NLP"></li>
<li class="task-list-item"><input type="checkbox" disabled> Intution and reason</li>
</ul>
<h3 id="negative-log-likelihood">Negative Log Likelihood<a aria-hidden="true" class="anchor-heading icon-link" href="#negative-log-likelihood"></a></h3>
<ul>
<li>Averaging the of training set gives us <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">NLL</code></li>
<li><img src="/notes/assets/images/2022-01-16-16-07-48.png" alt="NLL"></li>
</ul>
<br>
<ul>
<li>If we minimize the <em>NLL</em>, we can compute maximum likelihood estimate of <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">MLE</code></li>
<li><img src="/notes/assets/images/2022-01-16-16-08-57.png" alt="MLE"></li>
</ul>
<h1 id="regression">Regression<a aria-hidden="true" class="anchor-heading icon-link" href="#regression"></a></h1>
<ul>
<li><em>response</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span></span> is an continuous, real quantity</li>
</ul>
<h2 id="loss-function">Loss Function<a aria-hidden="true" class="anchor-heading icon-link" href="#loss-function"></a></h2>
<ul>
<li>here the loss function is quadratic - <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">l<sub>2</sub> loss</code></li>
<li><img src="/notes/assets/images/2022-01-16-16-11-07.png" alt="quadratic loss"></li>
<li>quadratic loss penalizes large <em>residuals</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>−</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">y-\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> more than small ones 
<ul>
<li>if the data has outliers, quadratic penalty can be very severe</li>
<li>in such cases we can use <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">l <sub>1</sub> loss</code></li>
</ul>
</li>
</ul>
<h2 id="empirical-risk">Empirical Risk<a aria-hidden="true" class="anchor-heading icon-link" href="#empirical-risk"></a></h2>
<ul>
<li>Averraging the quadraticl log function, we get the mean squared error <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">MSE</code></li>
<li><img src="/notes/assets/images/2022-01-16-17-59-02.png" alt="MSE"></li>
</ul>
<h3 id="negative-log-likelihood-1">Negative Log Likelihood<a aria-hidden="true" class="anchor-heading icon-link" href="#negative-log-likelihood-1"></a></h3>
<ul>
<li>Fixing the variance for simplicity and using the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>l</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">l_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> loss function, we get <em>NLL</em> as:</li>
<li><img src="/notes/assets/images/2022-01-16-18-08-38.png" alt="NLL"></li>
<li>this is proportional to MSE
<ul>
<li><strong>hence we can calculate maximum likelihood estimate by minmizing the MSE</strong></li>
</ul>
</li>
</ul>
<h2 id="capturing-uncertainity-1">Capturing Uncertainity<a aria-hidden="true" class="anchor-heading icon-link" href="#capturing-uncertainity-1"></a></h2>
<ul>
<li>In linear regression, output is assumed to <em>Gaussian</em> or <em>Normal</em></li>
<li><img src="/notes/assets/images/2022-01-16-18-02-12.png" alt="Gaussian"></li>
<li>Here the mean can be defined using the inputs, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mu = f(x_n;\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span>, and therefor the probability distribution is given by:</li>
<li><img src="/notes/assets/images/2022-01-16-18-05-09.png" alt="dist"></li>
</ul>
<h2 id="linear-regression">Linear Regression<a aria-hidden="true" class="anchor-heading icon-link" href="#linear-regression"></a></h2>
<ul>
<li>
<blockquote style="background-color: #43b02a20; padding:3px 2px; border-radius: 5px; border-left: 0.25em solid #43b02a; padding-left: 0.75em">When we fit the data using <b>linear function of the parameters</b>, it is known as linear regression </blockquote>
</li>
<li><img src="/notes/assets/images/2022-01-23-12-42-44.png">
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> <a href="https://github.com/probml/pyprobml/blob/master/scripts/linreg_residuals_plot.py">code</a></li>
</ul>
</li>
<li>we can fit a 1d data using a <em>simple linear regression</em> model of the form</li>
<li><img src="/notes/assets/images/2022-01-23-12-41-37.png"></li>
<li>here <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span></span> is <em>slope</em> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span></span> is <em>offset</em>, and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>=</mo><mo stretchy="false">(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta=(w,b)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mclose">)</span></span></span></span></span> are the parameters of the model</li>
<li>we minimize the squared error to get the least squares solution</li>
<li><img src="/notes/assets/images/2022-01-23-12-39-53.png"></li>
<li>If we have multiple <em>predictors</em>, we can have a <strong><em>multiple lineare regression</em></strong></li>
<li><img src="/notes/assets/images/2022-01-23-12-41-00.png"></li>
</ul>
<h2 id="polynomial-regression">Polynomial Regression<a aria-hidden="true" class="anchor-heading icon-link" href="#polynomial-regression"></a></h2>
<ul>
<li>The fitting can be improved by using a <strong><em>polynomial regression</em></strong> model of the form <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><mi>w</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>w</mi><mi>T</mi></msup><mi>ϕ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x;w) = w^T\phi(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\phi(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span> is a featue vector derived from the input </li>
<li><img src="/notes/assets/images/2022-01-23-12-47-00.png"></li>
<li><img src="/notes/assets/images/2022-01-23-12-55-41.png">
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> <a href="https://github.com/probml/pyprobml/blob/master/scripts/linreg_2d_surface_demo.py">code</a></li>
</ul>
</li>
<li>
<blockquote style="background-color: #43b02a20; padding:3px 2px; border-radius: 5px; border-left: 0.25em solid #43b02a; padding-left: 0.75em">It is important that the prediction function is a linear function of the parameter because a linear model induces a loss function MSE(θ) that has <b>unique global optimum</b></blockquote>
</li>
</ul>