<h1 id="5-knn">5-KNN<a aria-hidden="true" class="anchor-heading icon-link" href="#5-knn"></a></h1>
<h1 id="examplar-based-methods">Examplar based methods<a aria-hidden="true" class="anchor-heading icon-link" href="#examplar-based-methods"></a></h1>
<ul>
<li>in <em>parametric</em> models, after estimating the parameters from the training data, we no longer need that data</li>
</ul>
<br>
<ul>
<li>in <em>non-parametric</em> models, keep the training data
<ul>
<li>thus the effective number of parameters can grow with size of data <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">∣</mo><mo stretchy="false">∣</mo><mi>D</mi><mo stretchy="false">∣</mo><mo stretchy="false">∣</mo></mrow><annotation encoding="application/x-tex">\lvert\lvert D \rvert\rvert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">∣∣</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">∣∣</span></span></span></span></span></li>
</ul>
</li>
<li>such models can be defined in terms of dissimilarity or distance function between a point in the testing set <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span> and that in the training set <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> give by <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(x, x_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li>
<li>such approach is also called <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">instance-based</code> or <code style="background-color: #43b02a40; padding:3px 2px; border-radius: 5px">memory-based</code> learning</li>
</ul>
<h2 id="knn-classification">KNN classification<a aria-hidden="true" class="anchor-heading icon-link" href="#knn-classification"></a></h2>
<ul>
<li><strong><em>Assumption: similar datapoints have similar labels</em></strong></li>
<li>for a new input <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>, we look at the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span> nearest neighbors and determine a probability distribution for the label</li>
<li><img src="/notes/assets/images/2022-02-02-02-02-47.png"></li>
<li>there are two main parameters for <em>KNN</em> - number of neigbors <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></span> and the distance function <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo stretchy="false">(</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D()</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mopen">(</span><span class="mclose">)</span></span></span></span></span>.  </li>
<li><strong><em>A small value of k leads to overfitting and a large value of k leads to uncerfitting</em></strong></li>
</ul>
<h3 id="choosing-the-optimal-k">choosing the optimal k<a aria-hidden="true" class="anchor-heading icon-link" href="#choosing-the-optimal-k"></a></h3>
<p><img src="/notes/assets/images/2022-02-02-02-06-50.png"></p>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> <a href="https://github.com/probml/pyprobml/blob/master/scripts/knn_classify_demo.py">code</a></li>
</ul>